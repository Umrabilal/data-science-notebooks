{"cells":[{"cell_type":"markdown","id":"745197b1-1983-4730-8fbc-ef37ad7dcfbe","metadata":{"id":"745197b1-1983-4730-8fbc-ef37ad7dcfbe"},"source":["# This is a Spam mail detection project\n","# we are going to classify from the dataset contain with spam and Ham which email is Spam or ham\n","# 1-Problem defination\n","# 2-Dataset\n","# 3-Evaluation\n","# 4-Features\n","# 5-Modelling\n","# 6-Experimentation"]},{"cell_type":"markdown","id":"fa3f3206-3d8e-455f-bb00-0e3566b810a5","metadata":{"id":"fa3f3206-3d8e-455f-bb00-0e3566b810a5"},"source":["# 1-Problem defination\n","    based on the given data we need to predict which email is Spam or not spam"]},{"cell_type":"markdown","id":"32ce5dc1-72cc-4eff-b313-e65fa562b32a","metadata":{"id":"32ce5dc1-72cc-4eff-b313-e65fa562b32a"},"source":["# 2- Dataset\n","    We have the data and already have loaded it\n"]},{"cell_type":"markdown","id":"1ca99cc0-506a-4be7-95b1-b03989e15565","metadata":{"id":"1ca99cc0-506a-4be7-95b1-b03989e15565"},"source":["# 3-Evaluate\n","    In initial stages we need to make sure if our model gave us the accuracy of about 95%"]},{"cell_type":"markdown","id":"8cfc128b-e5ca-4a78-9b92-19d7742a3e31","metadata":{"id":"8cfc128b-e5ca-4a78-9b92-19d7742a3e31"},"source":["# 4-Features\n","    what feature are important and what feature column means what?\n","    label\n","    \n","Labels of Emails which can be either Spam or Ham\n","    \n","\n","te    xt\n","Emails da    ta\n","\n","labe    l_num\n","if spam it's 1, or else it's 0"]},{"cell_type":"code","execution_count":null,"id":"92d93e52-332e-4856-8daf-5a9185e5e6c0","metadata":{"id":"92d93e52-332e-4856-8daf-5a9185e5e6c0","outputId":"1892c1b0-3134-4d61-e048-5f8d150183f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (3.8.1)\n","Requirement already satisfied: click in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from nltk) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from nltk) (2024.4.16)\n","Requirement already satisfied: tqdm in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from nltk) (4.66.2)\n","Requirement already satisfied: colorama in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from click->nltk) (0.4.6)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install nltk"]},{"cell_type":"code","execution_count":null,"id":"002afbba-1e65-4da8-8d8f-4253bbdfcb5b","metadata":{"id":"002afbba-1e65-4da8-8d8f-4253bbdfcb5b","outputId":"f01ebff1-22ea-4f35-9577-2a4dfe2a16ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: seaborn in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (0.13.2)Note: you may need to restart the kernel to use updated packages.\n","\n","Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from seaborn) (1.24.3)\n","Requirement already satisfied: pandas>=1.2 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from seaborn) (2.1.4)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from seaborn) (3.8.0)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.25.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.0.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n","Requirement already satisfied: six>=1.5 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"]}],"source":["pip install seaborn"]},{"cell_type":"code","execution_count":null,"id":"c62b26a9-77b0-488b-afca-23376088fd78","metadata":{"id":"c62b26a9-77b0-488b-afca-23376088fd78","outputId":"edc20210-6d39-47c2-d77a-05bf788791a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wordcloud in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (1.9.3)\n","Requirement already satisfied: numpy>=1.6.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from wordcloud) (1.24.3)\n","Requirement already satisfied: pillow in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from wordcloud) (10.0.1)\n","Requirement already satisfied: matplotlib in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from wordcloud) (3.8.0)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n","Requirement already satisfied: six>=1.5 in c:\\users\\bilal\\desktop\\ml_project\\spam_filter_project\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install wordcloud"]},{"cell_type":"code","execution_count":null,"id":"701277e6-db38-4a47-92f8-89fc416e9f4b","metadata":{"id":"701277e6-db38-4a47-92f8-89fc416e9f4b"},"outputs":[],"source":["# Importing necessary libraries\n","import numpy as np                                                    # For numerical operations\n","import pandas as pd                                                   # For data manipulation and analysis\n","import string                                                         # Filter out all of the puncuation from the email text\n","\n","\n","import nltk                                                           # we need have to download something\n","# Importing NLTK libraries for text preprocessing\n","from nltk.corpus import stopwords                                     # For accessing a list of common stopwords\n","from nltk.stem.porter import PorterStemmer                            # For stemming words to their root forms\n","\n","\n","from sklearn.feature_extraction.text import CountVectorizer           # For converting text data into numerical feature vectors\n","from sklearn.model_selection import train_test_split                  # For splitting data into training and testing sets\n","\n","\n","# For building a random forest classifier model\n","from sklearn.ensemble import RandomForestClassifier"]},{"cell_type":"code","execution_count":null,"id":"2a420f50-6d4a-49d5-acda-92ea80f40731","metadata":{"id":"2a420f50-6d4a-49d5-acda-92ea80f40731","outputId":"2df394d6-ad6d-4992-f9a1-e21550ead1b0"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\Bilal\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["# Downloading NLTK's stopwords corpus\n","nltk.download(\"stopwords\")"]},{"cell_type":"code","execution_count":null,"id":"e18519d7-a996-4b4f-bd18-66ad0f6abe24","metadata":{"id":"e18519d7-a996-4b4f-bd18-66ad0f6abe24"},"outputs":[],"source":["# Reading the dataset from a CSV file into a pandas DataFrame\n","df = pd.read_csv('spam_ham_dataset.csv')"]},{"cell_type":"code","execution_count":null,"id":"4a85e80f-006a-4b36-b479-0aaf5ff9b68e","metadata":{"id":"4a85e80f-006a-4b36-b479-0aaf5ff9b68e","outputId":"734baf55-076b-47a5-f757-6c52562a9f23"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>label_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>605</td>\n","      <td>ham</td>\n","      <td>Subject: enron methanol ; meter # : 988291 thi...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2349</td>\n","      <td>ham</td>\n","      <td>Subject: hpl nom for january 9 , 2001 ( see at...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3624</td>\n","      <td>ham</td>\n","      <td>Subject: neon retreat ho ho ho , we ' re aroun...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4685</td>\n","      <td>spam</td>\n","      <td>Subject: photoshop , windows , office . cheap ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2030</td>\n","      <td>ham</td>\n","      <td>Subject: re : indian springs this deal is to b...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0 label                                               text  \\\n","0         605   ham  Subject: enron methanol ; meter # : 988291 thi...   \n","1        2349   ham  Subject: hpl nom for january 9 , 2001 ( see at...   \n","2        3624   ham  Subject: neon retreat ho ho ho , we ' re aroun...   \n","3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n","4        2030   ham  Subject: re : indian springs this deal is to b...   \n","\n","   label_num  \n","0          0  \n","1          0  \n","2          0  \n","3          1  \n","4          0  "]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"id":"900c8381-1fa3-40c0-af40-e38808dcf24a","metadata":{"id":"900c8381-1fa3-40c0-af40-e38808dcf24a"},"outputs":[],"source":["# Removing newline characters '\\r\\n' from the 'text' column and replacing them with spaces\n","df['text'] = df['text'].apply(lambda x: x.replace('\\r\\n', ' '))"]},{"cell_type":"code","execution_count":null,"id":"8fa4eb95-50e4-4a02-af91-53299ffcfaa3","metadata":{"id":"8fa4eb95-50e4-4a02-af91-53299ffcfaa3","outputId":"1861e131-84d7-452b-a35f-586eca6c8b6f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>label_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5166</th>\n","      <td>1518</td>\n","      <td>ham</td>\n","      <td>Subject: put the 10 on the ft the transport vo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5167</th>\n","      <td>404</td>\n","      <td>ham</td>\n","      <td>Subject: 3 / 4 / 2000 and following noms hpl c...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5168</th>\n","      <td>2933</td>\n","      <td>ham</td>\n","      <td>Subject: calpine daily gas nomination &gt; &gt; juli...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5169</th>\n","      <td>1409</td>\n","      <td>ham</td>\n","      <td>Subject: industrial worksheets for august 2000...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5170</th>\n","      <td>4807</td>\n","      <td>spam</td>\n","      <td>Subject: important online banking alert dear v...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Unnamed: 0 label                                               text  \\\n","5166        1518   ham  Subject: put the 10 on the ft the transport vo...   \n","5167         404   ham  Subject: 3 / 4 / 2000 and following noms hpl c...   \n","5168        2933   ham  Subject: calpine daily gas nomination > > juli...   \n","5169        1409   ham  Subject: industrial worksheets for august 2000...   \n","5170        4807  spam  Subject: important online banking alert dear v...   \n","\n","      label_num  \n","5166          0  \n","5167          0  \n","5168          0  \n","5169          0  \n","5170          1  "]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["df.tail()"]},{"cell_type":"code","execution_count":null,"id":"175e1ba5-80f8-4485-a521-6b1b7371dff4","metadata":{"id":"175e1ba5-80f8-4485-a521-6b1b7371dff4","outputId":"d556b565-16dc-41be-e1a1-437ad0bb9d2b"},"outputs":[{"data":{"text/plain":["\"Subject: enron methanol ; meter # : 988291 this is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary flow data provided by daren } . please override pop ' s daily volume { presently zero } to reflect daily activity you can obtain from gas control . this change is needed asap for economics purposes .\""]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Accessing the text from the first row of the 'text' column in the DataFrame\n","df.text.iloc[0]"]},{"cell_type":"code","execution_count":null,"id":"262ab6d8-5d86-4b4f-a54a-09c8516ad69b","metadata":{"id":"262ab6d8-5d86-4b4f-a54a-09c8516ad69b","outputId":"d13d907e-674f-4a38-9de2-84609af77901"},"outputs":[{"data":{"text/plain":["'Subject: hpl nom for january 9 , 2001 ( see attached file : hplnol 09 . xls ) - hplnol 09 . xls'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Accessing the text from the second row of the 'text' column in the DataFrame\n","df.text.iloc[1]"]},{"cell_type":"code","execution_count":null,"id":"30b1e5fb-3a14-4c4e-a260-ba20997c8e14","metadata":{"id":"30b1e5fb-3a14-4c4e-a260-ba20997c8e14","outputId":"78e79ea9-be0b-4f6a-bd2e-4e0deb5227cc"},"outputs":[{"data":{"text/plain":["\"Subject: neon retreat ho ho ho , we ' re around to that most wonderful time of the year - - - neon leaders retreat time ! i know that this time of year is extremely hectic , and that it ' s tough to think about anything past the holidays , but life does go on past the week of december 25 through january 1 , and that ' s what i ' d like you to think about for a minute . on the calender that i handed out at the beginning of the fall semester , the retreat was scheduled for the weekend of january 5 - 6 . but because of a youth ministers conference that brad and dustin are connected with that week , we ' re going to change the date to the following weekend , january 12 - 13 . now comes the part you need to think about . i think we all agree that it ' s important for us to get together and have some time to recharge our batteries before we get to far into the spring semester , but it can be a lot of trouble and difficult for us to get away without kids , etc . so , brad came up with a potential alternative for how we can get together on that weekend , and then you can let me know which you prefer . the first option would be to have a retreat similar to what we ' ve done the past several years . this year we could go to the heartland country inn ( www . . com ) outside of brenham . it ' s a nice place , where we ' d have a 13 - bedroom and a 5 - bedroom house side by side . it ' s in the country , real relaxing , but also close to brenham and only about one hour and 15 minutes from here . we can golf , shop in the antique and craft stores in brenham , eat dinner together at the ranch , and spend time with each other . we ' d meet on saturday , and then return on sunday morning , just like what we ' ve done in the past . the second option would be to stay here in houston , have dinner together at a nice restaurant , and then have dessert and a time for visiting and recharging at one of our homes on that saturday evening . this might be easier , but the trade off would be that we wouldn ' t have as much time together . i ' ll let you decide . email me back with what would be your preference , and of course if you ' re available on that weekend . the democratic process will prevail - - majority vote will rule ! let me hear from you as soon as possible , preferably by the end of the weekend . and if the vote doesn ' t go your way , no complaining allowed ( like i tend to do ! ) have a great weekend , great golf , great fishing , great shopping , or whatever makes you happy ! bobby\""]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Accessing the text from the third row of the 'text' column in the DataFrame\n","df.text.iloc[2]"]},{"cell_type":"code","execution_count":null,"id":"fefa18da-37ac-4bd9-b3fc-2d43d6f4eb9d","metadata":{"id":"fefa18da-37ac-4bd9-b3fc-2d43d6f4eb9d","outputId":"c3b6e540-45ae-4ec6-a596-7445e03deeb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5171 entries, 0 to 5170\n","Data columns (total 4 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   Unnamed: 0  5171 non-null   int64 \n"," 1   label       5171 non-null   object\n"," 2   text        5171 non-null   object\n"," 3   label_num   5171 non-null   int64 \n","dtypes: int64(2), object(2)\n","memory usage: 161.7+ KB\n"]}],"source":["# Displaying summary information about the DataFrame\n","df.info()"]},{"cell_type":"code","execution_count":null,"id":"fb1442b8-1075-40ac-b8db-7b0261966508","metadata":{"id":"fb1442b8-1075-40ac-b8db-7b0261966508"},"outputs":[],"source":["# Initializing a Porter stemmer and creating a corpus of stemmed text data\n","stemmer = PorterStemmer()                                                        # Initialize a Porter stemmer for word stemming\n","corpus = []                                                                      # Initialize an empty list to store the processed text data\n","\n","stopwords_set = set(stopwords.words('english'))                                  # Get a set of English stopwords\n","\n","# Iterate through each row of the DataFrame to preprocess the text data\n","for i in range(len(df)):\n","     # Convert the text to lowercase and tokenize it\n","    text = df['text'].iloc[i].lower()\n","    text = text.translate(str.maketrans(' ', ' ', string.punctuation)).split()\n","    # Apply stemming to each word in the text and remove stopwords\n","    text = [stemmer.stem(word) for word in text if word not in stopwords_set]\n","    # Join the stemmed words back into a single string and add it to the corpus\n","    text = ' '.join(text)\n","    corpus.append(text)"]},{"cell_type":"code","execution_count":null,"id":"9d8dc6d6-d57c-443b-ab36-ef4b2f747224","metadata":{"id":"9d8dc6d6-d57c-443b-ab36-ef4b2f747224","outputId":"e5e0a3ac-3ba6-4f96-d70e-5de160b15c03"},"outputs":[{"data":{"text/plain":["'subject hpl nom januari 9 2001 see attach file hplnol 09 xl hplnol 09 xl'"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Accessing the preprocessed text data of the second document in the corpus\n","corpus[1]"]},{"cell_type":"code","execution_count":null,"id":"c0372e91-a2c0-44d8-b4b6-528bda05a3a7","metadata":{"id":"c0372e91-a2c0-44d8-b4b6-528bda05a3a7","outputId":"eaf7561a-74c3-4742-d581-74e8052df91a"},"outputs":[{"data":{"text/plain":["\"Subject: enron methanol ; meter # : 988291 this is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary flow data provided by daren } . please override pop ' s daily volume { presently zero } to reflect daily activity you can obtain from gas control . this change is needed asap for economics purposes .\""]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["df.text.iloc[0]"]},{"cell_type":"code","execution_count":null,"id":"c00a5f69-3836-4d0b-ba64-e528b3dc1206","metadata":{"id":"c00a5f69-3836-4d0b-ba64-e528b3dc1206"},"outputs":[],"source":["# Creating feature vectors using CountVectorizer and splitting the data into training and testing sets\n","vectorizer = CountVectorizer()                                             # Initialize CountVectorizer for converting text to feature vectors\n","x = vectorizer.fit_transform(corpus).toarray()                             # Convert text corpus to a matrix of token counts\n","y = df.label_num                                                           # Assigning labels from the DataFrame to y\n","\n","# Splitting the data into training and testing sets with a ratio of 80% training and 20% testing\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =0.2)"]},{"cell_type":"code","execution_count":null,"id":"c79d0fa8-a2ea-46d2-918a-0ee8452f1d15","metadata":{"id":"c79d0fa8-a2ea-46d2-918a-0ee8452f1d15","outputId":"9793353b-61af-4a11-adb9-3a335411be7c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of x_train: (4136, 42637)\n","Shape of y_train: (4136,)\n"]}],"source":["# Printing the shapes of the training data and corresponding labels\n","print(\"Shape of x_train:\", x_train.shape)                              # Print the shape of the training data\n","print(\"Shape of y_train:\", y_train.shape)                              # Print the shape of the corresponding labels"]},{"cell_type":"code","execution_count":null,"id":"70ac7ac1-1416-4c31-95f5-abbb6f213ef9","metadata":{"id":"70ac7ac1-1416-4c31-95f5-abbb6f213ef9","outputId":"d602f6cd-1d16-4386-8b06-d754d35e9340"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1)</pre></div></div></div></div></div>"],"text/plain":["RandomForestClassifier(n_jobs=-1)"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["# Initializing a RandomForestClassifier and fitting it to the training data\n","clf = RandomForestClassifier(n_jobs=-1)                               # Initialize a RandomForestClassifier with parallel processing\n","clf.fit(x_train, y_train)                                             # Fit the classifier to the training data"]},{"cell_type":"code","execution_count":null,"id":"f6dfba69-1243-4b28-a2a5-ee35de5fc424","metadata":{"id":"f6dfba69-1243-4b28-a2a5-ee35de5fc424","outputId":"354bd204-af34-4176-954e-bb2f12679026"},"outputs":[{"data":{"text/plain":["0.9768115942028985"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["# Calculating the accuracy score of the trained classifier on the testing data\n","clf.score(x_test, y_test)"]},{"cell_type":"code","execution_count":null,"id":"ffe65935-0ad9-4ad0-8f3d-f7aec0d6897e","metadata":{"id":"ffe65935-0ad9-4ad0-8f3d-f7aec0d6897e"},"outputs":[],"source":["# Assigning the text of the 11th document in the DataFrame to the variable 'email_to_classify'\n","email_to_classify = df.text.values[10]"]},{"cell_type":"code","execution_count":null,"id":"1f291a77-7545-4a93-bd22-3909e1195bf4","metadata":{"id":"1f291a77-7545-4a93-bd22-3909e1195bf4"},"outputs":[],"source":["# Preprocessing the text of the email to classify\n","# 1. Convert the email text to lowercase, remove punctuation, and split into words\n","email_text = email_to_classify.lower().translate(str.maketrans(\" \",\" \", string.punctuation)).split()\n","# 2. Apply stemming to each word and remove stopwords\n","email_text = [stemmer.stem(word) for word in email_text if word not in stopwords_set]\n","# 3. Join the stemmed words back into a single string\n","email_text = ' '.join(email_text)\n","# 4. Create a corpus containing the preprocessed email text\n","email_corpus = [email_text]\n","# 5. Transform the email text into a feature vector using the same vectorizer as used for training data\n","x_email = vectorizer.transform(email_corpus)"]},{"cell_type":"code","execution_count":null,"id":"54f730d9-adc0-4eae-ad81-e1d7ddcfcd51","metadata":{"id":"54f730d9-adc0-4eae-ad81-e1d7ddcfcd51","outputId":"b3d93bc6-387f-4d12-ca58-2ebdb2717575"},"outputs":[{"data":{"text/plain":["array([1], dtype=int64)"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["# Predicting the label of the email text using the trained classifier\n","clf.predict(x_email)"]},{"cell_type":"code","execution_count":null,"id":"153cf8c9-2e01-414a-a38e-bdd537e5739a","metadata":{"id":"153cf8c9-2e01-414a-a38e-bdd537e5739a","outputId":"f0fe035d-d9c2-4e77-d7ac-9418d5643893"},"outputs":[{"data":{"text/plain":["1"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["# Accessing the label of the 16th document in the DataFrame\n","df.label_num.iloc[15]"]},{"cell_type":"code","execution_count":null,"id":"b73197e9-5627-45c1-b8aa-c7a552420eb1","metadata":{"id":"b73197e9-5627-45c1-b8aa-c7a552420eb1"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}